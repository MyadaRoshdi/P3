{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of labels -0.3211613\n",
      "(160, 320, 3)  shape of train samples\n",
      "size of training set 48216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (5, 5), activation=\"relu\")`\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (5, 5), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33751 samples, validate on 14465 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "lines = []\n",
    "i = 0\n",
    "with open('driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             lines.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "# create adjusted steering measurements for the side camera images\n",
    "correction = 0.01 # this is a parameter to tune\n",
    "\n",
    "images = []\n",
    "measurments = []\n",
    "for line in lines:\n",
    "    #print(line)\n",
    "    for i in range(3):\n",
    "        # get the image path from the file\n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = 'IMG/'+ filename\n",
    "        #print('current_path', current_path)\n",
    "        image = cv2.imread(current_path)\n",
    "        images.append(image)\n",
    "        # get the steering measurmement (labels) from the file\n",
    "        measurment = line[3]\n",
    "        if (i == 0):\n",
    "            measurments.append(float(measurment))\n",
    "        if (i == 1):\n",
    "             measurments.append(float(measurment) + correction)\n",
    "        if (i == 2):\n",
    "             measurments.append(float(measurment) - correction)\n",
    "\n",
    "# convert features and labels to numpy array as that's the format keras requires  \n",
    "print(\"Sample of labels\", measurments[4823] )\n",
    "#X_train = np.array(images)\n",
    "#y_train = np.array(measurments) \n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\"size of training set\", len(X_train))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Shuffle training data, NOTE: No need for that part as it will be done in the model.fit()\n",
    "#X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# Data Augmentation\n",
    "augmented_images, augmented_measurments = [], []\n",
    "for image,measurment in zip(images, measurments):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurments.append(measurment)\n",
    "    augmented_images.append(cv2.flip(image, 1)) #flip image 180 horizontally\n",
    "    augmented_measurments.append(measurment * -1.0) # reverse the steering angle\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurments) \n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "print(\"size of training set\", len(X_train))\n",
    "\n",
    "#print (\" Subset y-labels are\")\n",
    "#print(y_train[0:1000])\n",
    "    \n",
    "\n",
    "\n",
    "# build a very simple model to test on it\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Convolution2D(32, 3, 3, input_shape=(160, 320, 3)))\n",
    "# Preprocessing the data using Normalization and Mean-Center\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "# Using LeNet5 model \n",
    "model.add(Convolution2D(6, 5, 5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6, 5, 5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.3, shuffle=True, epochs=5)\n",
    "#x_test = X_train\n",
    "#y_test = y_train\n",
    "#model.fit(X_train, y_train, batch_size=128,epochs=7,verbose=1,validation_data=(x_test, y_test))\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "# you will notice that before the 7th-epoch, the validation loss was decreasing then after it increased, so to prevent overfittng, we can nb_epoch = 7\n",
    "\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('./small_traffic_set/small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "# Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
