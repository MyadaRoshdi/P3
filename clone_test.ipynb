{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) [NVIDIA](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) + cropping+ normalization + Data Augmenting 180-flipped images +  5-epochs + Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required libraries\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_preprocess(img):\n",
    "    #Applying GaussianBlur for image smooting and removing noise\n",
    "    n_img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    # convert from BGR to YUV\n",
    "    n_img = cv2.cvtColor(n_img, cv2.COLOR_BGR2YUV)\n",
    "    return n_img\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "samples = []\n",
    "i = 0\n",
    "# Parsing the .csv file and extracting lines in list samples.\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers are not included\n",
    "             samples.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "# Split validation and training samples with 20% of samples for validation        \n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "# sizes are multplied by 3, cause each line has 3- images representing center, left and right images \n",
    "print('size of original training_set= ', len(train_samples)*3)\n",
    "print('size of original validation_set= ', len(validation_samples)*3)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    '''\n",
    "    Using generators to be able to train and validate on limited memory \n",
    "    '''\n",
    "    correction = 0.2 # steering angle correction is a parameter to tune\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                # extract the center image path from the .cvs file\n",
    "                source_path= batch_sample[0]\n",
    "                # the following 3 lines is used to extract just the image name without local path on local machine where data is collected\n",
    "                filename =source_path.split('C:')[-1]\n",
    "                filename =source_path.split('\\\\')[-1]\n",
    "                filename =source_path.split('/')[-1]\n",
    "               # print('filename after line split: ', filename)\n",
    "                # update image path to the current folder on the AWS\n",
    "                current_path= 'data/IMG/'+filename\n",
    "                #print(\"center_image current_path is: \", current_path)\n",
    "                center_image = cv2.imread(current_path)\n",
    "                center_image = image_preprocess(center_image)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                images.append(cv2.flip(center_image, 1)) #flip image 180 horizontally\n",
    "                angles.append(center_angle * -1.0) # reverse the steering angle\n",
    "                \n",
    "                \n",
    "                name_left = 'data/IMG/'+batch_sample[1].split('\\\\')[-1]\n",
    "                name_left = 'data/IMG/'+batch_sample[1].split('/')[-1]\n",
    "               # print('filename after line split: ', name_left)\n",
    "                left_image = cv2.imread(name_left)\n",
    "                left_angle = center_angle + correction\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                name_right = 'data/IMG/'+batch_sample[2].split('\\\\')[-1]\n",
    "                name_right = 'data/IMG/'+batch_sample[2].split('/')[-1]\n",
    "                right_image = cv2.imread(name_right)\n",
    "                right_angle = center_angle - correction\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "\n",
    "            # Convert to numpy float arrays.\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            # Shuffle the data for every batch\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "#Import all keras required libraries      \n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "from keras import regularizers\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 60-pixels from top and 20 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((60,20), (0,0)),  input_shape = (160,320,3)))\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center and using trimmed image format to perform cropping\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(80,320,3),  output_shape = (80,320,3)))\n",
    "\n",
    "\n",
    "                    \n",
    "# Using NVIDIA model \n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2), kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2), kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "# Generate training and validation datasets and run the model in batches, where batch_size= 32\n",
    "train_generator = generator(train_samples)\n",
    "validation_generator = generator(validation_samples)\n",
    "\n",
    "samples_per_epoch = len(train_samples)\n",
    "batch_size = 32\n",
    "steps_per_epoch = samples_per_epoch/batch_size\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Capture the compiling start time \n",
    "start = time.time()\n",
    "\n",
    "history = model.fit_generator(train_generator, validation_steps=len(validation_samples), steps_per_epoch=steps_per_epoch, epochs=3, validation_data=validation_generator)\n",
    "# print time difference between start compiling and finishing\n",
    "print(\"Time fit_generator for %s samples: %s\" % (len(train_samples), time.time() - start))\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()          \n",
    "\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "\n",
    "# visualize model layout with pydot_ng\n",
    "#plot(model, to_file='model.png', show_shapes=True)\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
