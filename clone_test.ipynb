{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)  Lenet5 + cropping+ normalization + Data Augmenting 180-flipped images + 5-epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "lines = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             lines.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "# create adjusted steering measurements for the side camera images\n",
    "correction = 0.01 # this is a parameter to tune\n",
    "\n",
    "images = []\n",
    "measurments = []\n",
    "# use this section if you wanna use images from the 3-cameras\n",
    "#for line in lines:\n",
    "    #print(line)\n",
    " #   for i in range(3):\n",
    "        # get the image path from the file\n",
    "  #      source_path = line[i]\n",
    "   #     filename = source_path.split('/')[-1]\n",
    "    #    current_path = 'IMG/'+ filename\n",
    "        #print('current_path', current_path)\n",
    "     #   image = cv2.imread(current_path)\n",
    "      #  images.append(image)\n",
    "        # get the steering measurmement (labels) from the file\n",
    "       # measurment = line[3]\n",
    "        #if (i == 0):\n",
    "         #   measurments.append(float(measurment))\n",
    "        #if (i == 1):\n",
    "         #    measurments.append(float(measurment) + correction)\n",
    "        #if (i == 2):\n",
    "         #    measurments.append(float(measurment) - correction)\n",
    "            \n",
    "            \n",
    "  \n",
    "\n",
    "# use this section if you wanna use only the central camera image\n",
    "for line in lines:\n",
    "    #print(line)\n",
    "    # get the image path from the file\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = 'data/IMG/'+ filename\n",
    "    #print('current_path', current_path)\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "     # get the steering measurmement (labels) from the file\n",
    "    measurment = line[3]\n",
    "    measurments.append(float(measurment))\n",
    "        \n",
    "        \n",
    "        \n",
    "# convert features and labels to numpy array as that's the format keras requires  \n",
    "print(\"Sample of labels\", measurments[4823] )\n",
    "#X_train = np.array(images)\n",
    "#y_train = np.array(measurments) \n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\"size of training set\", len(X_train))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Shuffle training data, NOTE: No need for that part as it will be done in the model.fit()\n",
    "#X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# Data Augmentation\n",
    "augmented_images, augmented_measurments = [], []\n",
    "for image,measurment in zip(images, measurments):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurments.append(measurment)\n",
    "    augmented_images.append(cv2.flip(image, 1)) #flip image 180 horizontally\n",
    "    augmented_measurments.append(measurment * -1.0) # reverse the steering angle\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurments) \n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "print(\"size of training set\", len(X_train))\n",
    "\n",
    "#print (\" Subset y-labels are\")\n",
    "#print(y_train[0:1000])\n",
    "    \n",
    "\n",
    "\n",
    "# build a very simple model to test on it\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 50-pixels from top and 20 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Using LeNet5 model \n",
    "model.add(Convolution2D(6, 5, 5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6, 5, 5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.3, shuffle=True, epochs=5)\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "# you will notice that before the 7th-epoch, the validation loss was decreasing then after it increased, so to prevent overfittng, we can nb_epoch = 7\n",
    "\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)  [NVIDIA](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) + cropping+ normalization + Data Augmenting 180-flipped images + 5-epochs or 3-epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "lines = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             lines.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "# create adjusted steering measurements for the side camera images\n",
    "correction = 0.01 # this is a parameter to tune\n",
    "\n",
    "images = []\n",
    "measurments = []\n",
    "# use this section if you wanna use images from the 3-cameras\n",
    "#for line in lines:\n",
    "    #print(line)\n",
    " #   for i in range(3):\n",
    "        # get the image path from the file\n",
    "  #      source_path = line[i]\n",
    "   #     filename = source_path.split('/')[-1]\n",
    "    #    current_path = 'IMG/'+ filename\n",
    "        #print('current_path', current_path)\n",
    "     #   image = cv2.imread(current_path)\n",
    "      #  images.append(image)\n",
    "        # get the steering measurmement (labels) from the file\n",
    "       # measurment = line[3]\n",
    "        #if (i == 0):\n",
    "         #   measurments.append(float(measurment))\n",
    "        #if (i == 1):\n",
    "         #    measurments.append(float(measurment) + correction)\n",
    "        #if (i == 2):\n",
    "         #    measurments.append(float(measurment) - correction)\n",
    "            \n",
    "            \n",
    "  \n",
    "\n",
    "# use this section if you wanna use only the central camera image\n",
    "for line in lines:\n",
    "    #print(line)\n",
    "    # get the image path from the file\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = 'data/IMG/'+ filename\n",
    "    #print('current_path', current_path)\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "     # get the steering measurmement (labels) from the file\n",
    "    measurment = line[3]\n",
    "    measurments.append(float(measurment))\n",
    "        \n",
    "        \n",
    "        \n",
    "# convert features and labels to numpy array as that's the format keras requires  \n",
    "print(\"Sample of labels\", measurments[4823] )\n",
    "#X_train = np.array(images)\n",
    "#y_train = np.array(measurments) \n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\"size of training set\", len(X_train))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Shuffle training data, NOTE: No need for that part as it will be done in the model.fit()\n",
    "#X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# Data Augmentation\n",
    "augmented_images, augmented_measurments = [], []\n",
    "for image,measurment in zip(images, measurments):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurments.append(measurment)\n",
    "    augmented_images.append(cv2.flip(image, 1)) #flip image 180 horizontally\n",
    "    augmented_measurments.append(measurment * -1.0) # reverse the steering angle\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurments) \n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "print(\"size of training set\", len(X_train))\n",
    "\n",
    "#print (\" Subset y-labels are\")\n",
    "#print(y_train[0:1000])\n",
    "    \n",
    "\n",
    "\n",
    "# build a very simple model to test on it\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 50-pixels from top and 20 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Using NVIDIA model \n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, validation_split=0.3, shuffle=True, epochs=3)\n",
    "          \n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()          \n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "\n",
    "# visualize model layout with pydot_ng\n",
    "#plot(model, to_file='model.png', show_shapes=True)\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) [NVIDIA](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) + cropping+ normalization + Data Augmenting 180-flipped images +  5-epochs + Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing all required libraries\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "# Images resizing and pre-processing\n",
    "def image_preprocess(img):\n",
    "    \n",
    "    # original Image shape is:  160x320x3 while input shape for the Nvidia model is:  66x200x3\n",
    "    # crop to 40x320x3\n",
    "    #n_img = img[50:140,0,0]\n",
    "    n_img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    # scale to 66x200x3 (same as nVidia), and as suggested by the Cheatsheet\n",
    "    #n_img = cv2.resize(n_img,(200, 66), interpolation = cv2.INTER_AREA)\n",
    "    # convert to YUV color space (as Hinted in the project )\n",
    "    n_img = cv2.cvtColor(n_img, cv2.COLOR_BGR2YUV)\n",
    "    return n_img\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of original training_set=  8588\n",
      "size of original validation_set=  2148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "269/268 [==============================] - 1273s 5s/step - loss: 0.0490 - val_loss: 0.0409\n",
      "Epoch 2/3\n",
      "269/268 [==============================] - 1273s 5s/step - loss: 0.0448 - val_loss: 0.0411\n",
      "Epoch 3/3\n",
      "269/268 [==============================] - 1273s 5s/step - loss: 0.0436 - val_loss: 0.0402\n",
      "Time fit_generator for 8588 samples: 3820.6451411247253\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5483e5278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "samples = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             samples.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "        \n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print('size of original training_set= ', len(train_samples))\n",
    "print('size of original validation_set= ', len(validation_samples))\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                source_path= batch_sample[0]\n",
    "                filename =source_path.split(':/')[-1]\n",
    "                filename =source_path.split('/')[-1]\n",
    "                #print('filename after line split: ', filename)\n",
    "                current_path= 'data/IMG/'+filename\n",
    "                #print(\"center_image current_path is: \", current_path)\n",
    "                center_image = cv2.imread(current_path)\n",
    "                center_image = image_preprocess(center_image)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                images.append(cv2.flip(center_image, 1)) #flip image 180 horizontally\n",
    "                angles.append(center_angle * -1.0) # reverse the steering angle\n",
    "                \n",
    "                \n",
    "                name_left = 'data/IMG/'+batch_sample[1].split('/')[-1]\n",
    "                left_image = cv2.imread(name_left)\n",
    "                left_angle = center_angle + 0.2\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                name_right = 'data/IMG/'+batch_sample[2].split('/')[-1]\n",
    "                right_image = cv2.imread(name_right)\n",
    "                right_angle = center_angle - 0.2\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "\n",
    "            # Convert to numpy float arrays.\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            # Shuffle the data for every batch\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "#print(\"size of training set\", len(X_train))            \n",
    "\n",
    "\n",
    "\n",
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 60-pixels from top and 20 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((60,20), (0,0)),  input_shape = (160,320,3)))\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center and using trimmed image format to perform cropping\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(80,320,3),  output_shape = (80,320,3)))\n",
    "\n",
    "\n",
    "                    \n",
    "# Using NVIDIA model \n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "# Generate training and validation datasets and run the model in batches, where batch_size= 32\n",
    "train_generator = generator(train_samples)\n",
    "validation_generator = generator(validation_samples)\n",
    "\n",
    "samples_per_epoch = len(train_samples)\n",
    "batch_size = 32\n",
    "steps_per_epoch = samples_per_epoch/batch_size\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "start = time.time()\n",
    "#history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, validation_data=validation_generator,nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "history = model.fit_generator(train_generator, validation_steps=len(validation_samples), steps_per_epoch=steps_per_epoch, epochs=3, validation_data=validation_generator)\n",
    "print(\"Time fit_generator for %s samples: %s\" % (len(train_samples), time.time() - start))\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()          \n",
    "\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "\n",
    "# visualize model layout with pydot_ng\n",
    "#plot(model, to_file='model.png', show_shapes=True)\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4) This section using Nvidia  images from the thre cameras with steering correction (Not compiling sofar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "samples = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             samples.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "        \n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# create adjusted steering measurements for the side camera images\n",
    "\n",
    "\n",
    "#images = []\n",
    "#measurments = []\n",
    "# use this section if you wanna use images from the 3-cameras\n",
    "#for line in lines:\n",
    "    #print(line)\n",
    " #   for i in range(3):\n",
    "        # get the image path from the file\n",
    "  #      source_path = line[i]\n",
    "   #     filename = source_path.split('/')[-1]\n",
    "    #    current_path = 'IMG/'+ filename\n",
    "        #print('current_path', current_path)\n",
    "     #   image = cv2.imread(current_path)\n",
    "      #  images.append(image)\n",
    "        # get the steering measurmement (labels) from the file\n",
    "       # measurment = line[3]\n",
    "        #if (i == 0):\n",
    "         #   measurments.append(float(measurment))\n",
    "        #if (i == 1):\n",
    "         #    measurments.append(float(measurment) + correction)\n",
    "        #if (i == 2):\n",
    "         #    measurments.append(float(measurment) - correction)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name_center = 'data/IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name_center)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "                name_left = 'data/IMG/'+batch_sample[1].split('/')[-1]\n",
    "                left_image = cv2.imread(name_left)\n",
    "                left_angle = center_angle + correction\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                name_right = 'data/IMG/'+batch_sample[2].split('/')[-1]\n",
    "                right_image = cv2.imread(name_right)\n",
    "                right_angle = center_angle - correction\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "#print(\"size of training set\", len(X_train))            \n",
    "\n",
    "\n",
    "\n",
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center and using trimmed image format to perform cropping\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0, input_shape=(160, 320, 3)))\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 70-pixels from top and 25 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "                    \n",
    "# Using NVIDIA model \n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples)\n",
    "validation_generator = generator(validation_samples)\n",
    "\n",
    "samples_per_epoch = len(train_samples)\n",
    "batch_size = 32\n",
    "steps_per_epoch = samples_per_epoch/batch_size\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "start = time.time()\n",
    "#history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, validation_data=validation_generator,nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "history = model.fit_generator(train_generator, validation_steps=len(validation_samples), steps_per_epoch=steps_per_epoch, epochs=3, validation_data=validation_generator)\n",
    "print(\"Time fit_generator for %s samples: %s\" % (len(train_samples), time.time() - start))\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()          \n",
    "\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "\n",
    "# visualize model layout with pydot_ng\n",
    "#plot(model, to_file='model.png', show_shapes=True)\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5) drive.py sends RGB images to the model; cv2.imread() reads images in BGR format!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_conv(img):\n",
    "    '''\n",
    "    Method for preprocessing images: this method is the same used in drive.py, except this version uses\n",
    "    BGR to YUV and drive.py uses RGB to YUV (due to using cv2 to read the image here, where drive.py images are \n",
    "    received in RGB)\n",
    "    '''\n",
    "    # original shape: 160x320x3, input shape for neural net: 66x200x3\n",
    "    # crop to 105x320x3\n",
    "    #new_img = img[35:140,:,:]\n",
    "    # crop to 40x320x3\n",
    "# new_img = img[50:140,:,:]\n",
    "    # apply subtle blur\n",
    "    new_img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    # scale to 66x200x3 (same as nVidia)\n",
    "#    new_img = cv2.resize(new_img,(200, 66), interpolation = cv2.INTER_AREA)\n",
    "    # scale to ?x?x3\n",
    "    #new_img = cv2.resize(new_img,(80, 10), interpolation = cv2.INTER_AREA)\n",
    "    # convert to YUV color space (as nVidia paper suggests)\n",
    "    new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2YUV)\n",
    "    return new_img\n",
    "print ('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "samples = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             samples.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "        \n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# create adjusted steering measurements for the side camera images\n",
    "\n",
    "\n",
    "#images = []\n",
    "#measurments = []\n",
    "# use this section if you wanna use images from the 3-cameras\n",
    "#for line in lines:\n",
    "    #print(line)\n",
    " #   for i in range(3):\n",
    "        # get the image path from the file\n",
    "  #      source_path = line[i]\n",
    "   #     filename = source_path.split('/')[-1]\n",
    "    #    current_path = 'IMG/'+ filename\n",
    "        #print('current_path', current_path)\n",
    "     #   image = cv2.imread(current_path)\n",
    "      #  images.append(image)\n",
    "        # get the steering measurmement (labels) from the file\n",
    "       # measurment = line[3]\n",
    "        #if (i == 0):\n",
    "         #   measurments.append(float(measurment))\n",
    "        #if (i == 1):\n",
    "         #    measurments.append(float(measurment) + correction)\n",
    "        #if (i == 2):\n",
    "         #    measurments.append(float(measurment) - correction)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name_center = 'data/IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name_center)\n",
    "                center_image = img_conv(center_image)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                images.append(cv2.flip(center_image, 1)) #flip image 180 horizontally\n",
    "                angles.append(center_angle * -1.0) # rev\n",
    "                \n",
    "                name_left = 'data/IMG/'+batch_sample[1].split('/')[-1]\n",
    "                left_image = cv2.imread(name_left)\n",
    "                left_image = img_conv(left_image)\n",
    "                left_angle = center_angle + correction\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                name_right = 'data/IMG/'+batch_sample[2].split('/')[-1]\n",
    "                right_image = cv2.imread(name_right)\n",
    "                right_image = img_conv(right_image)\n",
    "                right_angle = center_angle - correction\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "#print(' shape of train samples', X_train[0].shape())\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "#print(\"size of training set\", len(X_train))            \n",
    "\n",
    "\n",
    "\n",
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center and using trimmed image format to perform cropping\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0, input_shape=( 160, 320, 3)))\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 70-pixels from top and 25 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "                    \n",
    "# Using NVIDIA model \n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples)\n",
    "validation_generator = generator(validation_samples)\n",
    "\n",
    "samples_per_epoch = len(train_samples)\n",
    "batch_size = 32\n",
    "steps_per_epoch = samples_per_epoch/batch_size\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "start = time.time()\n",
    "#history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, validation_data=validation_generator,nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "history = model.fit_generator(train_generator, validation_steps=len(validation_samples), steps_per_epoch=steps_per_epoch, epochs=3, validation_data=validation_generator)\n",
    "print(\"Time fit_generator for %s samples: %s\" % (len(train_samples), time.time() - start))\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()          \n",
    "\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "\n",
    "# visualize model layout with pydot_ng\n",
    "plot(model, to_file='model.png', show_shapes=True)\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
