{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)  Lenet5 + cropping+ normalization + Data Augmenting 180-flipped images + 5-epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "lines = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             lines.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "# create adjusted steering measurements for the side camera images\n",
    "correction = 0.01 # this is a parameter to tune\n",
    "\n",
    "images = []\n",
    "measurments = []\n",
    "# use this section if you wanna use images from the 3-cameras\n",
    "#for line in lines:\n",
    "    #print(line)\n",
    " #   for i in range(3):\n",
    "        # get the image path from the file\n",
    "  #      source_path = line[i]\n",
    "   #     filename = source_path.split('/')[-1]\n",
    "    #    current_path = 'IMG/'+ filename\n",
    "        #print('current_path', current_path)\n",
    "     #   image = cv2.imread(current_path)\n",
    "      #  images.append(image)\n",
    "        # get the steering measurmement (labels) from the file\n",
    "       # measurment = line[3]\n",
    "        #if (i == 0):\n",
    "         #   measurments.append(float(measurment))\n",
    "        #if (i == 1):\n",
    "         #    measurments.append(float(measurment) + correction)\n",
    "        #if (i == 2):\n",
    "         #    measurments.append(float(measurment) - correction)\n",
    "            \n",
    "            \n",
    "  \n",
    "\n",
    "# use this section if you wanna use only the central camera image\n",
    "for line in lines:\n",
    "    #print(line)\n",
    "    # get the image path from the file\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = 'data/IMG/'+ filename\n",
    "    #print('current_path', current_path)\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "     # get the steering measurmement (labels) from the file\n",
    "    measurment = line[3]\n",
    "    measurments.append(float(measurment))\n",
    "        \n",
    "        \n",
    "        \n",
    "# convert features and labels to numpy array as that's the format keras requires  \n",
    "print(\"Sample of labels\", measurments[4823] )\n",
    "#X_train = np.array(images)\n",
    "#y_train = np.array(measurments) \n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\"size of training set\", len(X_train))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Shuffle training data, NOTE: No need for that part as it will be done in the model.fit()\n",
    "#X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# Data Augmentation\n",
    "augmented_images, augmented_measurments = [], []\n",
    "for image,measurment in zip(images, measurments):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurments.append(measurment)\n",
    "    augmented_images.append(cv2.flip(image, 1)) #flip image 180 horizontally\n",
    "    augmented_measurments.append(measurment * -1.0) # reverse the steering angle\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurments) \n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "print(\"size of training set\", len(X_train))\n",
    "\n",
    "#print (\" Subset y-labels are\")\n",
    "#print(y_train[0:1000])\n",
    "    \n",
    "\n",
    "\n",
    "# build a very simple model to test on it\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 50-pixels from top and 20 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Using LeNet5 model \n",
    "model.add(Convolution2D(6, 5, 5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6, 5, 5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.3, shuffle=True, epochs=5)\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "# you will notice that before the 7th-epoch, the validation loss was decreasing then after it increased, so to prevent overfittng, we can nb_epoch = 7\n",
    "\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)  [NVIDIA](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) + cropping+ normalization + Data Augmenting 180-flipped images + 5-epochs or 3-epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "lines = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             lines.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "# create adjusted steering measurements for the side camera images\n",
    "correction = 0.01 # this is a parameter to tune\n",
    "\n",
    "images = []\n",
    "measurments = []\n",
    "# use this section if you wanna use images from the 3-cameras\n",
    "#for line in lines:\n",
    "    #print(line)\n",
    " #   for i in range(3):\n",
    "        # get the image path from the file\n",
    "  #      source_path = line[i]\n",
    "   #     filename = source_path.split('/')[-1]\n",
    "    #    current_path = 'IMG/'+ filename\n",
    "        #print('current_path', current_path)\n",
    "     #   image = cv2.imread(current_path)\n",
    "      #  images.append(image)\n",
    "        # get the steering measurmement (labels) from the file\n",
    "       # measurment = line[3]\n",
    "        #if (i == 0):\n",
    "         #   measurments.append(float(measurment))\n",
    "        #if (i == 1):\n",
    "         #    measurments.append(float(measurment) + correction)\n",
    "        #if (i == 2):\n",
    "         #    measurments.append(float(measurment) - correction)\n",
    "            \n",
    "            \n",
    "  \n",
    "\n",
    "# use this section if you wanna use only the central camera image\n",
    "for line in lines:\n",
    "    #print(line)\n",
    "    # get the image path from the file\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = 'data/IMG/'+ filename\n",
    "    #print('current_path', current_path)\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "     # get the steering measurmement (labels) from the file\n",
    "    measurment = line[3]\n",
    "    measurments.append(float(measurment))\n",
    "        \n",
    "        \n",
    "        \n",
    "# convert features and labels to numpy array as that's the format keras requires  \n",
    "print(\"Sample of labels\", measurments[4823] )\n",
    "#X_train = np.array(images)\n",
    "#y_train = np.array(measurments) \n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\"size of training set\", len(X_train))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Shuffle training data, NOTE: No need for that part as it will be done in the model.fit()\n",
    "#X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# Data Augmentation\n",
    "augmented_images, augmented_measurments = [], []\n",
    "for image,measurment in zip(images, measurments):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurments.append(measurment)\n",
    "    augmented_images.append(cv2.flip(image, 1)) #flip image 180 horizontally\n",
    "    augmented_measurments.append(measurment * -1.0) # reverse the steering angle\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurments) \n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "print(\"size of training set\", len(X_train))\n",
    "\n",
    "#print (\" Subset y-labels are\")\n",
    "#print(y_train[0:1000])\n",
    "    \n",
    "\n",
    "\n",
    "# build a very simple model to test on it\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 50-pixels from top and 20 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Using NVIDIA model \n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, validation_split=0.3, shuffle=True, epochs=3)\n",
    "          \n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()          \n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "\n",
    "# visualize model layout with pydot_ng\n",
    "#plot(model, to_file='model.png', show_shapes=True)\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) [NVIDIA](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) + cropping+ normalization + Data Augmenting 180-flipped images +  5-epochs + Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "samples = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             samples.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "        \n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = 'data/IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "#print(\"size of training set\", len(X_train))            \n",
    "\n",
    "\n",
    "\n",
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center and using trimmed image format to perform cropping\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0, input_shape=(160, 320, 3)))\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 70-pixels from top and 25 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "                    \n",
    "# Using NVIDIA model \n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples)\n",
    "validation_generator = generator(validation_samples)\n",
    "\n",
    "samples_per_epoch = len(train_samples)\n",
    "batch_size = 32\n",
    "steps_per_epoch = samples_per_epoch/batch_size\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "start = time.time()\n",
    "#history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, validation_data=validation_generator,nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "history = model.fit_generator(train_generator, validation_steps=len(validation_samples), steps_per_epoch=steps_per_epoch, epochs=3, validation_data=validation_generator)\n",
    "print(\"Time fit_generator for %s samples: %s\" % (len(train_samples), time.time() - start))\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()          \n",
    "\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "\n",
    "# visualize model layout with pydot_ng\n",
    "#plot(model, to_file='model.png', show_shapes=True)\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4) This section using Nvidia  images from the thre cameras with steering correction (Not compiling sofar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "201/200 [==============================] - 583s 3s/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 2/3\n",
      "201/200 [==============================] - 579s 3s/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 3/3\n",
      "201/200 [==============================] - 580s 3s/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Time fit_generator for 6428 samples: 1742.8202633857727\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FfW9//HXOwkhJmxhU3ZQoGXfwdZq8brhStWqWDcQ\n6tVqrdrrvVpbbb21ta1Va10RUKm4oFUvP5dqrVprlV1ANmURZFMW2ZdA4PP7YyZhcsgyCTk5WT7P\nx2MenJn5zpzPORnyycx85/uRmeGcc85VtrRUB+Ccc6528gTjnHMuKTzBOOecSwpPMM4555LCE4xz\nzrmk8ATjnHMuKTzBuJSS9KSkX8dsu0LSycmOyYGk9ySNSXUcpZFkkjqnOg5XMk8wzjnnksITjHO1\nnKSM6vTe5Y0nlfG7w+MJxpUpvDR1s6R5knZKGi/pSElvSNou6W1JuZH250haIGlLeKmlW2RdP0mz\nw+2eB7IS3ussSXPCbT+U1DtmjE9KejiMaYekf0s6StL9kjZLWiypX6R9a0l/lbRB0ueSro+sGyzp\nozCGdZIelJQZWW+Srpa0JGzzkCSVENdgSTMlbZP0laR7I+suk7RS0iZJt0UvASZeOpQ0VNLqyPwt\nkpaF3+NCSedG1o0MP/99kjYBvwyXXylpUfh9vCmpQ2SbU8LvaKukB4FiP0/YNi3y/pskTZbUNFzX\nMfx+Rkv6AninuGVh29KOkxWS/kfSPGBnWUlGUmNJE8Of50pJP5eUFq7rLOmf4WfbGB53KHCfpPXh\nz+cTST1Lex9XTmbmk0+lTsAKYCpwJNAGWA/MBvoRJIh3gDvCtl2BncApQD3gv4GlQGY4rQRuDNd9\nH9gH/Drctl+47yFAOnBF+N71I3GcXEKMTwIbgQGRmD4HLg/39Wvg3bBtGjALuD2M6WhgOXBauH4A\ncCyQAXQEFgE3RN7LgFeBJkB7YAMwrIS4PgIuC183AI4NX3cHdgAnAPWBe4H8gs8Xfp5fR/YzFFgd\nmb8AaB1+lovC77xVuG5kuK8fh5/hCGB4+HPoFi77OfBh2L45sD38edQLfz75wJgSPtNPwuOhbRj7\nY8Cz4bqO4fczEcgJ37u4ZSUeJ5Gf9RygHXBECXEY0Dl8PRH4P6Bh+H6fAaPDdc8Ct4XfVRbwnXD5\naeFx0IQgoXYr+A59qqTfHakOwKfqP4X/2S+JzP8VeCQy/2PglfD1L4DJkXVpwJrwF+QJwFpAkfUf\ncjDBPAL8b8J7fwp8NxJHaQnm8YSYFkXmewFbwtdDgC8Str8VeKKEfd8AvByZt4JfUuH8ZOCWErZ9\nH/gV0Dxh+e3Ac5H5HGAvMRNMMe8zBxgevh5ZzOd7o+AXbuTnsgvoQJCEp0bWCVhNyQlmEXBSZL4V\nwR8KBQnZgKMj64tbVuJxEvlZX1nGcWlAZ4I/IPYC3SPr/hN4L3w9ERgLtE3Y/j8IEtGxQFqq/5/V\nxskvkbm4voq83l3MfIPwdWuCsxQAzOwAsIrgzKc1sMbC/92hlZHXHYCfhpdMtkjaQvAXbOtKjrED\n0DrhfX5GcIaGpK6SXpX0paRtwG8I/sqP+jLyeldk34lGE/y1vljSDElnhctbE3wvAJjZTmBTzM+J\npMsjlxK3AD0TYlyVsEkH4E+R9l8TJJKCn0s0Fitm+8R9vRzZ1yJgP+H3V8L7Jy4r7TgpbR/FaU5w\nFhQ9llZG9vXfBJ91enhJ7srwPd8BHgQeAtZLGiupUcz3dDF4gnGVbS3BLyAguM5NkCTWAOuANgn3\nK9pHXq8C7jKzJpEp28yereQYVwGfJ7xPQzM7I1z/CLAY6GJmjQiST4n3JEpjZkvM7GKgJfA74EVJ\nOQTfRbuCdpKygWaRTXcC2ZH5oyJtOwCPA9cBzcysCTA/IcbEYdJXAf+Z8JmPMLMPi4lF0flirAJO\nT9hXlpmtKeX9E5eVdpyUto/ibCQ4g+oQWda+YF9m9qWZ/dDMWhOc2TyssHuzmT1gZgMILll2BW6O\n+Z4uBk8wrrJNBs6UdJKkesBPgTyCS2EfEVzbv15SPUnnAYMj2z4OXC1pSHgDNkfSmZIaVnKM04Ht\n4U3kIySlS+opaVC4viGwDdgh6ZvANRV9I0mXSmoR/oW+JVx8AHgROEvSdxR0ILiTov8f5wBnSGoq\n6SiCy3QFcgh++W4I32MUwRlMaR4FbpXUI9ymsaQLwnWvAT0knRfeTL+eSEIrYV93FXQSkNRC0vAy\n3j9RacdJuZjZ/nB/d0lqGMZ1E/B0GN8FktqGzTcTfHcHJA0Kj7V6BAl9D8HPxlUSTzCuUpnZp8Cl\nwJ8J/rI8GzjbzPaa2V7gPIJ7BF8T3Jx+KbLtTOCHBJctNhPc9B2ZhBj3A2cBfQk6AmwExgGNwyb/\nBfyA4Mb348Dzh/F2w4AFknYAfwJGmNluM1sAXAs8Q3AGsZngvkeBvwBzCe5FvBWNwcwWAn8kSNhf\nEdxf+ndpQZjZywRnUM+Fl/3mA6eH6zYSdBq4m+AyXZcy9vcnYArwlqTtBDf8h5TxPSTGU+JxUp79\nRPyYIEksBz4g+F4nhOsGAdPCn8EU4CdmthxoRPDz3UxwSW0T8IcKvr8rhopeDnfOpYqkFQQ31t9O\ndSzOVQY/g3HOOZcUnmCcc84lhV8ic845lxR+BuOccy4p6vQgcs2bN7eOHTumOgznnKtRZs2atdHM\nWpTVrk4nmI4dOzJz5sxUh+GcczWKpJVlt/JLZM4555LEE4xzzrmk8ATjnHMuKer0PRjnXOrt27eP\n1atXs2fPnlSH4hJkZWXRtm1b6tWrV6HtPcE451Jq9erVNGzYkI4dO6LiC4O6FDAzNm3axOrVq+nU\nqVOF9uGXyJxzKbVnzx6aNWvmyaWakUSzZs0O68zSE4xzLuU8uVRPh/tz8QRTAbv25vPLKQvYumtf\nqkNxzrlqyxNMBSxcu41J01Yy6snp7MzLT3U4zrnDsGXLFh5++OEKbXvGGWewZcuWUtvcfvvtvP12\n1VdgeOWVV1i4cGGVv2+UJ5gKGNixKX++uB9zVm3hqr/MZM++/akOyTlXQaUlmPz80v+AfP3112nS\npEmpbe68805OPvnkCsdXUZ5garBhPVvxh+/34d9LN3HdMx+zb79XWnWuJrrllltYtmwZffv25eab\nb+a9997j+OOP55xzzqF79+4AfO9732PAgAH06NGDsWPHFm7bsWNHNm7cyIoVK+jWrRs//OEP6dGj\nB6eeeiq7d+8GYOTIkbz44ouF7e+44w769+9Pr169WLx4MQAbNmzglFNOoUePHowZM4YOHTqwcePG\nInHu37+fkSNH0rNnT3r16sV9990HwLJlyxg2bBgDBgzg+OOPZ/HixXz44YdMmTKFm2++mb59+7Js\n2bKkf4/FSWo3ZUnDCMqrpgPjzOzuhPUK158B7AJGmtnscN0EgrK2683skHrjkn4K3AO0CEu+IulW\nYDSwH7jezN5M1mcDOH9AW3buzef2/1vAf70wl/su7Etamt+sdK6ifvX/FrBw7bZK3Wf31o244+we\nJa6/++67mT9/PnPmzAHgvffeY/bs2cyfP7+we+6ECRNo2rQpu3fvZtCgQZx//vk0a9asyH6WLFnC\ns88+y+OPP86FF17IX//6Vy699NJD3q958+bMnj2bhx9+mHvuuYdx48bxq1/9iv/4j//g1ltv5W9/\n+xvjx48/ZLs5c+awZs0a5s+fD1B4ae6qq67i0UcfpUuXLkybNo0f/ehHvPPOO5xzzjmcddZZfP/7\n36/YF1cJkpZgJKUDDwGnENQanyFpSlhPvMDpBPW/uxDU9H6Eg7W9nySozT6xmH23A04Fvogs6w6M\nAHoArYG3JXUN668nzeXf6siOvHx+/7dPyamfwV3f6+k9Ypyr4QYPHlzk2Y8HHniAl19+GYBVq1ax\nZMmSQxJMp06d6Nu3LwADBgxgxYoVxe77vPPOK2zz0ksvAfDBBx8U7n/YsGHk5uYest3RRx/N8uXL\n+fGPf8yZZ57Jqaeeyo4dO/jwww+54IILCtvl5eVV8FNXvmSewQwGlprZcgBJzwHDgWiCGQ5MtKDq\n2VRJTSS1MrN1Zva+pI4l7Ps+4L+B/0vY13Nmlgd8LmlpGMNHlfmhivOjoZ3ZsSefh99bRoP6Gdx6\n+jc9yThXAaWdaVSlnJycwtfvvfceb7/9Nh999BHZ2dkMHTq02GdD6tevX/g6PT298BJZSe3S09PL\nvMcTlZuby9y5c3nzzTd59NFHmTx5Mvfffz9NmjQpPPuqbpJ5D6YNsCoyvzpcVt42RUgaDqwxs7kV\n2ZekqyTNlDRzw4YNpX+Ccrj5tG9w+bc6MPb95Tz4ztJK269zLrkaNmzI9u3bS1y/detWcnNzyc7O\nZvHixUydOrXSYzjuuOOYPHkyAG+99RabN28+pM3GjRs5cOAA559/Pr/+9a+ZPXs2jRo1olOnTrzw\nwgtA8PT93LlzY32uqlCjbvJLygZ+Btxe0X2Y2VgzG2hmA1u0KLNeTnli45dn9+C8fm34498/Y8IH\nn1favp1zydOsWTOOO+44evbsyc0333zI+mHDhpGfn0+3bt245ZZbOPbYYys9hjvuuIO33nqLnj17\n8sILL3DUUUfRsGHDIm3WrFnD0KFD6du3L5deeim//e1vAZg0aRLjx4+nT58+9OjRg//7v+DCzogR\nI/jDH/5Av379UnaTX8HVqSTsWPoW8EszOy2cvxXAzH4bafMY8J6ZPRvOfwoMNbN14XxH4NWCm/yS\negH/IOgQANAWWEtwKWxUdP+S3gzfv8RLZAMHDrTKLjiWv/8A1z4zmzcXfMXvz+/NhYPaVer+natt\nFi1aRLdu3VIdRkrl5eWRnp5ORkYGH330Eddcc021uexV3M9H0iwzG1jWtsm8BzMD6CKpE7CG4Ab8\nDxLaTAGuC+/PDAG2FiSX4pjZJ0DLgnlJK4CBZrZR0hTgGUn3Etzk7wJMr8TPE0tGehoPXNyPMU/N\n5JaX5pFTP4Mze7eq6jCcczXIF198wYUXXsiBAwfIzMzk8ccfT3VIlSJpCcbM8iVdB7xJ0E15gpkt\nkHR1uP5R4HWCLspLCc5KRhVsL+lZYCjQXNJq4A4zO7Tv3sH3WyBpMkEngnzg2mT3ICtJ/Yx0Hrts\nAFdMmM4Nz39MdmY6J36zZdkbOufqpC5duvDxxx+nOoxKl7RLZDVBMi6RRW3bs48fPD6VJV/t4Kkr\nB3Ps0c3K3si5OsYvkVVvh3OJrEbd5K9pGmXV46lRg2nXNJvRT85gzqrSxyxyzrnaxBNMkjVrUJ+n\nRw+haYNMrpgwnU+/TG23QeecqyqeYKrAUY2zmDT6WLLqpXHp+Gms2Lgz1SE551zSeYKpIu2bZfP0\n6CHsP2BcMm4aa7cU/5Svc676a9CgAQBr164tcayvoUOHUtY93vvvv59du3YVzscZ/r+yrVixgmee\neSYp+/YEU4W6HNmQiVcOZtvufVw6bhobd1SfMYOcc+XXunXrwpGSKyIxwcQZ/r+yeYKpRXq2acyE\nUYNYu3U3l42f7lUxnUuxW265hYceeqhw/pe//CX33HMPO3bs4KSTTiocWr/gCfmoFStW0LNnMNj7\n7t27GTFiBN26dePcc88tMhbZNddcw8CBA+nRowd33HEHEAyguXbtWk488UROPPFE4ODw/wD33nsv\nPXv2pGfPntx///2F71dSWYCoF154gZ49e9KnTx9OOOEEIBju/+abb2bQoEH07t2bxx57rPDz/+tf\n/6Jv376FJQAqS1KH63fFG9SxKWMvG8iYp2Yy8snpPD16CDn1/UfhHG/cAl9+Urn7PKoXnH53iasv\nuugibrjhBq699loAJk+ezJtvvklWVhYvv/wyjRo1YuPGjRx77LGcc845JQ5k+8gjj5Cdnc2iRYuY\nN28e/fv3L1x311130bRpU/bv389JJ53EvHnzuP7667n33nt59913ad68eZF9zZo1iyeeeIJp06Zh\nZgwZMoTvfve75ObmxioLcOedd/Lmm2/Spk2bwktu48ePp3HjxsyYMYO8vDyOO+44Tj31VO6++27u\nueceXn311Qp9vaXxM5gUOaFrCx64uB/zVm/lhxO9KqZzqdKvXz/Wr1/P2rVrmTt3Lrm5ubRr1w4z\n42c/+xm9e/fm5JNPZs2aNXz11Vcl7uf9998v/EXfu3dvevfuXbhu8uTJ9O/fn379+rFgwYIyK01+\n8MEHnHvuueTk5NCgQQPOO+88/vWvfwHxygIcd9xxjBw5kscff5z9+4PfLW+99RYTJ06kb9++DBky\nhE2bNrFkyZJyfVfl5X82p9Cwnkfxh+/35qbJc7numY955NL+1Ev3nO/qsFLONJLpggsu4MUXX+TL\nL7/koosuAoJBJDds2MCsWbOoV68eHTt2LHaY/rJ8/vnn3HPPPcyYMYPc3FxGjhxZof0UiFMW4NFH\nH2XatGm89tprDBgwgFmzZmFm/PnPf+a0004r0va9996rcCxl8d9mKXZe/7b87/AevL3oK/7rhbns\nP1B3R1ZwLlUuuuginnvuOV588cXC4l1bt26lZcuW1KtXj3fffZeVK1eWuo8TTjih8Gb5/PnzmTdv\nHgDbtm0jJyeHxo0b89VXX/HGG28UblPSkPrHH388r7zyCrt27WLnzp28/PLLHH/88bE/z7Jlyxgy\nZAh33nknLVq0YNWqVZx22mk88sgj7NsX3Pf97LPP2LlzZ1KH9fczmGrgsm91ZEfefn73t8VkZ2bw\nm3O9KqZzValHjx5s376dNm3a0KpVMDjtJZdcwtlnn02vXr0YOHAg3/zmN0vdxzXXXMOoUaPo1q0b\n3bp1Y8CAAQD06dOHfv368c1vfpN27dpx3HHHFW5z1VVXMWzYMFq3bs27775buLx///6MHDmSwYMH\nAzBmzBj69etXYpXMRDfffDNLlizBzDjppJPo06cPvXv3ZsWKFfTv3x8zo0WLFrzyyiv07t2b9PR0\n+vTpw8iRI7nxxhvL89WVysciS+JYZOX1+78t5uH3lvHD4zvxszO6eZJxdYKPRVa9Vdfh+l053Xza\nN9iRl8/j//qchln1uP6kLqkOyTnnKswTTDVSUBVzR14+9/79MxrUz+DK73RKdVjOOVchnmCqmbQ0\n8fvze7Mrbz93vrqQBvUzvCqmq/XMzC8JV0OHewvFe5FVQxnpafzp4r6c0LUFt7w0j1fnrU11SM4l\nTVZWFps2bTrsX2aucpkZmzZtIisrq8L78DOYaqp+RjqPXRpWxXxuDjmZGV4V09VKbdu2ZfXq1WzY\nsCHVobgEWVlZtG3btsLbey+yatSLrDjRqphPjhrMt47xqpjOudSqFhUtJQ2T9KmkpZJuKWa9JD0Q\nrp8nqX9k3QRJ6yXNT9jmf8O2cyS9Jal1uLyjpN3h8jmSHk3mZ6sqjbLqMfHKIbRvms2Yp7wqpnOu\n5khagpGUDjwEnA50By6W1D2h2elAl3C6Cngksu5JYFgxu/6DmfU2s77Aq8DtkXXLzKxvOF1dOZ8k\n9ZrmZPL0mCE0a1CfKyZMZ/GX21IdknPOlSmZZzCDgaVmttzM9gLPAcMT2gwHJlpgKtBEUisAM3sf\n+Dpxp2YW/e2aA9SJa3xHNspi0pghQVXMcdP53KtiOuequWQmmDbAqsj86nBZedscQtJdklYBl1D0\nDKZTeHnsn5KKHbhH0lWSZkqaWdNuKrZrms2kMUM4YMalXhXTOVfN1chuymZ2m5m1AyYB14WL1wHt\nw0tnNwHPSGpUzLZjzWygmQ1s0aJF1QVdSTq3LFoVc8N2r4rpnKuekplg1gDRJwTbhsvK26Y0k4Dz\nAcwsz8w2ha9nAcuAruWMuUbo2aYxT4waxLqte7hs/DSviumcq5aSmWBmAF0kdZKUCYwApiS0mQJc\nHvYmOxbYambrStuppOgAXcOBxeHyFmHHAiQdTdBxYHnlfJTqZ2DHpoy9fADLN+xk5JPT2ZmXn+qQ\nnHOuiKQlGDPLJ7h89SawCJhsZgskXS2poIfX6wRJYCnwOPCjgu0lPQt8BHxD0mpJo8NVd0uaL2ke\ncCrwk3D5CcA8SXOAF4GrzeyQTgK1yfFdvCqmc6768gctq/mDlnG8/PFqbnx+Lid3a8kjlw7wqpjO\nuaSqFg9auqpxbr+2/O/3evL2ovX8dLJXxXTOVQ9lJhhJF0hqGL7+uaSXok/cu+rhsmM78D/DvsmU\nuWv5+Suf+MCBzrmUi3MG8wsz2y7pO8DJwHiKPnHvqolrhh7DtScew7PTV3HXa4s8yTjnUirOaMoF\nd47PBMaa2WuSfp3EmNxh+K9Tv8GOPfmM+yCoivmTk70qpnMuNeIkmDWSHgNOAX4nqT5+76baksQd\nZ/dgR95+7nv7MxpkZTDaq2I651IgToK5kGDQyXvMbEs4VtjNyQ3LHY60NPG783uxa28+//vqQhrU\nT+eiQe1THZZzro6JcybSCnjNzJZIGgpcAExPalTusGWkp3H/iL58t2sLbnnpE/7fXK+K6ZyrWnES\nzF+B/ZI6A2MJhnZ5JqlRuUpRPyOdRy8dwKAOTbnx+Tm8s/irVIfknKtD4iSYA+FT+ecBfzazmwnO\nalwNcERmOuNGDqRbq0Zc/fRsPly2MdUhOefqiDgJZp+ki4HLCQp8AdRLXkiusjXKqsdTVw6mQ9Ns\nfvjUTD7+YnOqQ3LO1QFxEswo4FvAXWb2uaROwF+SG5arbNGqmCOfmOFVMZ1zSVdmgjGzhcB/AZ9I\n6gmsNrPfJT0yV+kKqmIeUS/dq2I655IuzlAxQ4ElwEPAw8Bnkk5IclwuSdo1zebpSFXMNV4V0zmX\nJHEukf0RONXMvmtmJwCnAfclNyyXTJ1bNgiqYu7xqpjOueSJk2DqmdmnBTNm9hl+k7/G69mmMU+M\nHMSXXhXTOZckcRLMTEnjJA0Np8eBml9ExRWpinnFE9PZ4VUxnXOVKE6CuQZYCFwfTgvDZa4WOL5L\nC/78g358smYrP3zKq2I65ypPnF5keWZ2r5mdF073mZlftK9FTutxFPdc0Jupn2/i2kmz2bf/QKpD\ncs7VAiUmGEmfSJpX0hRn55KGSfpU0lJJtxSzXpIeCNfPixYykzRB0npJ8xO2+d+w7RxJb0lqHVl3\na7ivTyWdFu8rcBBWxRzek38sXs9NXhXTOVcJShtN+azD2bGkdIKuzacAq4EZkqaEz9UUOB3oEk5D\nCAqZDQnXPQk8CExM2PUfzOwX4XtcD9wOXC2pOzAC6AG0Bt6W1NXM/JpPTJce24Edefnc/cZicjLT\n+e15vZCU6rCcczVUiQnGzFYe5r4HA0vNbDmApOeA4QT3cAoMByZaUHpxqqQmklqZ2Toze19Sx2Li\nij6CngMU/Kk9HHguvHz3uaSlYQwfHebnqFOu/u4x7NiTz4PvLqVB/QxuO7ObJxnnXIXEqQdTUW2A\nVZH51Rw8OymtTRtgXWk7lnQXwdhoW4ETI/uaWsy+XDn99NSu7MjzqpjOucNTIytTmtltZtYOmARc\nV55tJV0laaakmRs2bEhOgDWcJG4/qzvfH9CW+97+jHH/Wp7qkJxzNVCpCUZSuqRJFdz3GoLaMQXa\nhsvK26Y0k4Dzy7MvMxtrZgPNbGCLFi3K8VZ1S1qauPu8XpzR6yh+/doinpv+RapDcs7VMKUmmPAG\neQdJmRXY9wygi6RO4fYjgCkJbaYAl4e9yY4FtppZWZfHotdrhgOLI/saIal+OOJzF7zy5mHJSE/j\n/ov68d2uLbj1Za+K6Zwrnzj3YJYD/5Y0BSgcftfM7i1tIzPLl3Qd8CaQDkwwswWSrg7XPwq8DpwB\nLAV2EZQGAEDSs8BQoLmk1cAdZjYeuFvSN4ADwEqgYH8LJE0m6ESQD1zrPcgOX2ZGGo9eOoArJkzn\nxufnkJ2Zzkndjkx1WM65GkBBB65SGkh3FLfczH6VlIiq0MCBA23mTB/1Jo7te/ZxybhpLP5yO0+O\nGsS3j2me6pCccykiaZaZDSyzXVkJJrLDBgBmtuMwY6s2PMGUz+ade7lo7Ees2bybp8cMoV/73FSH\n5JxLgbgJJk49mJ6SPgYWAAskzZLUozKCdDVLbk4mT48eQvOGQVXMReu8KqZzrmRxuimPBW4ysw5m\n1gH4KfB4csNy1VXLRlk8PTqoinnZ+Oks31BrTmidc5UsToLJMbN3C2bM7D2CJ+hdHVVQFdO8KqZz\nrhRxEsxySb+Q1DGcfk7Qs8zVYZ1bNuCpKwezPS/fq2I654oVJ8FcCbQAXgL+CjQPl7k6rmebxjw5\n6mBVzC279qY6JOdcNVLmk/zAbWZ2vZn1N7MBZnaDmW2uovhcNTegQ1Mev3wgyzfsZOQTM7wqpnOu\nUJwn+b9TRbG4Guo7XZrzoFfFdM4liHOJ7GNJUyRdJum8ginpkbka5dQeR/HHC/ow9fNN/MirYjrn\niDdUTBawCfiPyDIjuCfjXKHv9WvDzr353PbyfG58fg5/GtGP9DSvJeNcXVVqggnvwcwzs/uqKB5X\nw10ypAM79uTz2zcW06B+hlfFdK4OKzXBmNl+SRcDnmBcbP/53WPYkZfPn99ZSk79DH7uVTGdq5Pi\nXCL7t6QHgecpOpry7KRF5Wq8m07pyvY9+Yz/4HMaZmVww8ldUx2Sc66KxUkwfcN/74wsM4rek3Gu\niIKqmDvz8rn/7SU0qJ/BmOOPTnVYzrkqVGaCMbMTy2rjXHHS0sTd5/dm1979/Pq1ReTUz+Diwe1T\nHZZzrorEGU35SEnjJb0RzneXNDr5obnaID1N3HdRX4Z+owU/e/kTpnhVTOfqjDjPwTxJUJWydTj/\nGXBDsgJytU9mRhqPXDKAQR2bctPzc/jHoq9SHZJzrgrESTDNzWwyQYlizCwf8Ee1XbkckZnO+CsG\n0r11I66ZNJsPl21MdUjOuSSLk2B2SmpGcGMfSccCW5MalauVGmbV46lRg+nYLJsxT81k9hc+pJ1z\ntVmcBHMTMAU4RtK/gYnAj+PsXNIwSZ9KWirplmLWS9ID4fp5kvpH1k2QtF7S/IRt/iBpcdj+ZUlN\nwuUdJe2WNCecHo0To6taBVUxWzSsz8gJ070qpnO1WJkJJnze5bvAt4H/BHqY2byytgtHAXgIOB3o\nDlwsqXvIn19UAAAgAElEQVRCs9OBLuF0FfBIZN2TwLBidv13oKeZ9Sa4H3RrZN0yM+sbTleXFaNL\njYKqmDn1M7hs/DSviulcLRXnDAYzyzezBWY238z2xdz3YGCpmS03s73Ac8DwhDbDgYkWmAo0kdQq\nfM/3ga+LieWt8D4QwFSgbcx4XDXSrmk2fxk9BDO4dNw0Vm/eleqQnHOVLFaCqaA2wKrI/OpwWXnb\nlOZK4I3IfKfw8tg/JR1f3AaSrpI0U9LMDRs2lOOtXGXr3LIBE0cfrIq5fvueVIfknKtEyUwwSSXp\nNiAfmBQuWge0N7O+BPeNnpHUKHE7MxtrZgPNbGCLFi2qLmBXrB6tG/PkqMGs357H5eOne1VM52qR\nEhOMpP6lTTH2vQZoF5lvGy4rb5viYhsJnAVcYmYGYGZ5ZrYpfD0LWAb4AFg1wIAOuYVVMa/wqpjO\n1RqlncH8MZweAqYBY4HHw9cPxdj3DKCLpE6SMoERBL3RoqYAl4e9yY4FtprZutJ2KmkY8N/AOWa2\nK7K8RdixAElHE3QcWB4jTlcNHNe5OQ9d0p/5a7Yy5qkZXhXTuVqgxARjZieG45CtA/qHl5UGAP2I\ncZYR3oi/jmAUgEXAZDNbIOlqSQU9vF4nSAJLCZLXjwq2l/Qs8BHwDUmrI8PTPAg0BP6e0B35BGCe\npDnAi8DVZnZIJwFXfZ3S/UjuvbAP0z7/mh9Nms3efK+K6VxNpvAKU8kNpAVm1qOsZTXRwIEDbebM\nmakOwyWYNG0lt708nzN7t+IBr4rpXLUjaZaZDSyrXZzh+udJGgc8Hc5fApT5HIxzFXXJkA7szMvn\nN68vpkFmBnef71UxnauJ4iSYUcA1wE/C+fcp+kCkc5XuqhOOYceefB4Iq2L+4iyviulcTROnHsye\n8D7H62b2aRXE5BwAN57Sle15+Uz4d1AV88ZTvFOgczVJnHow5wBzgL+F830lJfYGc67SSeIXZ3bn\nwoFt+dM/lvD4+94p0LmaJM4lsjsIhn15D8DM5kjqlMygnCuQliZ+e15vdubt567Xg6qYPxjiVTGd\nqwniJJh9ZrY14fp36V3PnKtEBVUxd+7N57ZXPiGnfjrD+5ZnRCHnXCrEGSpmgaQfAOmSukj6M/Bh\nkuNyrojMjDQevXQAgzs25aeT5/L2Qq+K6Vx1FyfB/BjoAeQBzxAUG/OSya7KZdVLZ9wVA+nRuhE/\nemY2Hy71qpjOVWelJphw6JU7zew2MxsUTj83Mx/21qVEw6x6PDlqMJ2a5TBmolfFdK46KzXBmNl+\n4DtVFItzseTmZPKX0YNpGVbFXLjWq2I6Vx3FuUT2saQpki6TdF7BlPTInCtFy0ZZPD0mqIp5+YRp\nLPOqmM5VO3ESTBawCfgP4OxwOiuZQTkXR9vcbJ4e41UxnauuyhzssjbzwS5rh4VrtzFi7Ec0zclk\n8tXfomXDrFSH5FytFnewyzhP8mdJulbSw5ImFEyVE6Zzh69760Y8EVbFvGycV8V0rrqIc4nsL8BR\nwGnAPwmqTm5PZlDOlVdBVczPN+3kignTvSqmc9VAnATT2cx+Aew0s6eAM4EhyQ3LufI7rnNzHv5B\nf+av3cboJ70qpnOpFifB7Av/3SKpJ9AYaJm8kJyruJPDqpjTV3zNNU/P8qqYzqVQnAQzVlIu8Atg\nCrAQ+H1So3LuMAzv24a7vteLdz/dwI2T57D/QN3tyOJcKpWZYMxsnJltNrN/mtnRZtbSzB6Ns3NJ\nwyR9KmmppFuKWS9JD4Tr50nqH1k3QdJ6SfMTtvmDpMVh+5clNYmsuzXc16eSTosTo6udfjCkPbed\n0Y3X5q3j1pfmccCTjHNVrszRlCXdXtxyM7uzjO3SgYeAU4DVwAxJU8xsYaTZ6UCXcBpCUCmz4P7O\nk8CDwMSEXf8duNXM8iX9DrgV+B9J3YERBOOmtQbeltQ1HI3A1UE/POFotufl88A/lpBTP4Pbz+ru\nVTGdq0JxLpHtjEz7CZJCxxjbDQaWmtlyM9sLPAcMT2gzHJhogalAE0mtAMzsfeDrxJ2a2VtmVtBF\naCpBr7aCfT1nZnlm9jmwNIzB1WE3ntyFK4/rxBP/XsF9by9JdTjO1SlxSib/MTov6R7gzRj7bgOs\nisyv5tDeZ8W1aQOsi7F/gCuB5yP7mlrMvoqQdBVwFUD79l64qraTxC/O6saOvH088I8lNKifzlUn\nHJPqsJyrE+IUHEuUzcGzhpSRdBuQD0wqz3ZmNhYYC8GT/EkIzVUz0sGqmL95fTEN6tfzqpjOVYE4\n92A+4WAFy3SgBVDq/ZfQGqBdZL5tuKy8bYqLaSTBeGgn2cGxbiq0L1c3FFTF3OVVMZ2rMnHuwZzF\nwUEuTwVam9mDMbabAXSR1ElSJsEN+CkJbaYAl4e9yY4FtppZqZfHJA0D/hs4x8yioxtOAUZIqi+p\nE0HHgekx4nR1RGZGGo+EVTFvmjyXv3tVTOeSKk6C2R6ZdgONJDUtmEraKLwRfx3B/ZpFwGQzWyDp\naklXh81eB5YT3JB/HPhRwfaSngU+Ar4habWk0eGqB4GGwN8lzZH0aPh+C4DJBM/p/A241nuQuURZ\n9dIZP3IQPds05tpnZvNvr4rpXNKUOZqypBUEl542AwKaAF+Eq83Mjk5mgMnkoynXXVt27eWix6ay\navMu/jJ6CAM65KY6JOdqjEobTZnguZOzzay5mTUjuGT2lpl1qsnJxdVtTbIz+cuYoCrmqCems2Dt\n1lSH5FytEyfBHGtmrxfMmNkbwLeTF5JzVaNlw0hVzPHTvSqmc5UsToJZK+nnkjqG023A2mQH5lxV\naJubzaQxQ5C8KqZzlS1OgrmYoGvyy+HUIlzmXK1wdIsGTLxyCDvz8rlk3DTWb9uT6pCcqxXiDHb5\ntZn9xMz6AQOB283skCFcnKvJurduxJNXDmbD9jwuGz+dzTu9KqZzhytOyeRnJDWSlAN8AiyUdHPy\nQ3OuavVvn8u4sCrmyCems33PvrI3cs6VKM4lsu5mtg34HvAG0Am4LKlROZci3w6rYi5Yu43RT81k\n915/lMq5ioqTYOpJqkeQYKaY2T4ODh3jXK1zcvcj+eOFfZix4muumeRVMZ2rqDgJ5jFgBZADvC+p\nA7AtmUE5l2rD+7bhN+f24r1PN3Dj814V07mKiDNc/wPAAwXzkr4ATkxmUM5VBxcPbs/OvHx+/doi\nsjPT+d35vUlL84JlzsVV7uH6w9GL88ts6FwtMOb4o9m+J58/hVUx7zjbq2I6F1dF6sE4V6fccHIX\nduTlM/6Dz2mUlcFNp34j1SE5VyN4gnGuDJL4+Znd2LEnnwfeWUqDrAyviulcDLESjKRvAx2j7c1s\nYpJicq7akcRvzuvFjr35XhXTuZjiVLT8C3AMMAcoeCjAAE8wrk5JTxP3XdiX3Xv3e1VM52KIcwYz\nkOBhS++n6eq8zIw0Hr6kPyOfmM5Nk+dyRL10Tu1xVKrDcq5aivMczHzA/wc5F8qql864K4KqmNc9\n8zEfLPGqmM4VJ06CaU4w/tibkqYUTMkOzLnqrEH9DJ4aNYijW+Tww4kzmbXSx391LlGcBPNLgmFi\nfgP8MTKVSdIwSZ9KWirplmLWS9ID4fp5kvpH1k2QtF7S/IRtLpC0QNIBSQMjyztK2i1pTjg9GidG\n5yqqSXYmE0cP5shG9Rn5xAyviulcgjjD9f+zuKms7SSlAw8BpwPdgYsldU9odjrQJZyuAh6JrHsS\nGFbMrucD5wHvF7NumZn1Daery4rRucNVUBWzoVfFdO4QcYbrP1bSDEk7JO2VtF9SnLHIBgNLzWy5\nme0FngOGJ7QZDky0wFSgiaRWAGb2PnDIdQczW2Rmn8Z4f+eqRNvcbJ6OVMVc9bVXxXQO4l0ie5Cg\nguUS4AhgDMGZSVnaAKsi86vDZeVtUx6dwstj/5R0fHENJF0laaakmRs2bDiMt3LuoKNbNOAvo4Oq\nmJeO96qYzkG8BIOZLQXSzWy/mT1B8ZeuUm0d0N7M+gI3Ac9IapTYyMzGmtlAMxvYokWLKg/S1V7d\nWjXiqbAq5qXjp3lVTFfnxUkwuyRlAnMk/V7SjTG3WwO0i8y3DZeVt00sZpZnZpvC17OAZUDXiuzL\nuYrq1z6XcVcMZMWmXVzhVTFdHRcnUVwWtrsO2EmQEM6Psd0MoIukTmGCGgEkdm+eAlwe9iY7Fthq\nZutiRx8hqUXYsQBJRxN0HFhekX05dzi+fUxQFXOhV8V0dVycXmQrAQGtzOxXZnZTeMmsrO3yCZLS\nm8AiYLKZLZB0taSCHl6vEySBpcDjwI8Ktpf0LPAR8A1JqyWNDpefK2k18C3gNUlvhpucAMyTNAd4\nEbjazPzhBJcSJ3c/knsv6utVMV2dprJGgJF0NnAPkGlmnST1Be40s3OqIsBkGjhwoM2cOTPVYbha\n7LnpX3DLS59wRq+jeGBEPzLSY932dK5akzTLzAaW1S7OWGS/JOhy/B6Amc2R1OmwonOujhgxuD07\nCqtifsLvvSqmq0PiJJh9ZrY1oYqfD3zpXExjjj+aHXn53P/2Ehp4VUxXh8RJMAsk/QBIl9QFuB74\nMLlhOVe7/OSkLmzfE1TFbJiVwU+9KqarA+JcEP4x0APIA54FtgE3JDMo52qbgqqYIwa148/vLOWx\nfy5LdUjOJV2ZZzBmtgu4LZyccxUkibvO7cWOvHx++8ZiGmRlcMmQDqkOy7mkiVPRciDwMw4tmdw7\neWE5Vzulp4n7LgqqYv78lfnkZGbwvX5eFdPVTnHuwUwCbgY+Abwzv3OHqV56Gg9d0p9RT8zgpy/M\nJTvTq2K62inOPZgNZjbFzD43s5UFU9Ijc64Wy6qXzuNXDKSXV8V0tVicBHOHpHGSLpZ0XsGU9Mic\nq+Ua1M/gSa+K6WqxOAlmFNCXYATls8PprGQG5VxdUVAV86jGWV4V09U6cRLMoHB4+yvMbFQ4XZn0\nyJyrIxKrYi5d71UxXe0QJ8F8WEypY+dcJWrT5Agm/fBYJHlVTFdrxEkwxxLUgvlU0jxJn0ial+zA\nnKtrOjXP4S+jB7N7334uGTeND5duZNfe/FSH5VyFxRlNudgnwWpDT7IKj6a8Zyss+n/QvCs07wJH\n5FZ+cK7O+viLzVw+fjrb8/JJTxPdWzWif/sm9O+Qy4AOubRpcoSPZeZSKu5oymUmmNqswglm5Ufw\nRKRqdHbzg8mmeZfgdbPO0KQDpMd51Mi5orbu3sfslZuZFU5zVm1h976gcNmRjeozoEMu/dvn0r9D\nLj1aN6J+RnqKI3Z1iSeYGCqcYPbnw5aVsPEz2Lgk+HfT0uDfXZsOtkvPhKbHQPPOYQLqCs26BPNZ\njSvvg7haL3//ARZ/uZ3ZXxxMOqs37wYgMyON3m0aB0knTDwtGtZPccSuNvMEE0NSCo7t+vpg0okm\nnq8/B4uUzm1w5MGznmZdDr5u3A7SvCiVK9tX2/Ywe+XmwqQzf8029u4PBtto3zS7MOEMaJ/LN45q\nSLrXoXGVxBNMDFVa0TJ/L2xeESadJUWT0J7Isw8ZWcHltSKJp3Pwun6DqonV1Uh79u1nwdqtzFq5\nmdkrtzBz5WY27sgDICcznb7tmzAgvKzWr30ujY+ol+KIXU1VLRKMpGHAn4B0YJyZ3Z2wXuH6M4Bd\nwEgzmx2um0DwQOd6M+sZ2eYCgiqb3YDBZjYzsu5WYDSwH7jezN4sLb5qUTLZDHZuDJNOwSW38PWW\nlWCR4d8atQmTT9eDiad512C53/R1CcyM1Zt3F15Sm/3FZhat28aB8L981yMbFN7HGdAhl6Ob53jn\nARdLyhOMpHTgM+AUYDUwA7jYzBZG2pxBUG/mDGAI8CczGxKuOwHYAUxMSDDdCAbdfAz4r4IEEz6r\n8yxBeefWwNtAV7PodamiqkWCKU1+Hny9/NDEs2kp5G072K5ediTxRDoaND0GMrNTF7+rdnbm5TN3\n1ZYg6XyxmdkrN7NtT9AVOje7XmHC6d8+lz7tGpOd6Z1U3KHiJphkHj2DgaVmtjwM6DlgOLAw0mY4\nQQIxYKqkJpJamdk6M3tfUsfEnZrZonB/iauGA8+ZWR7wuaSlYQwfVe7HqkIZ9aFlt2CKMoMdX0Uu\nsy0JzoBWT4f5f6VIRevG7SOdDCKX3Roe5Wc9dVBO/Qy+3bk53+7cHIADB4zlG3cUnuXMWrmZfyxe\nD1DYRbrwXk6HXFo3zvKzHBdbMhNMG2BVZH41wVlKWW3aAOsq+H5Ti9lXEZKuAq4CaN++fQXephqQ\nggTR8CjodHzRdft2w6ZlRTsYbPwMZv8F9u082C6zYfGJp+nRUC+raj+PS5m0NNG5ZUM6t2zIRYOC\n/w9bdu3l4y+2FCac52es4skPVwBFu0gP6JBLj9aNyczwTimueHXu/NfMxgJjIbhEluJwKl+9I+Co\nnsEUZQbb1iZ0MFgCK/4N854/2E5p0KR9pEt1pIdbTgs/66kDmmRncuI3W3LiN1sCB7tIz4r0WHv9\nky8B7yLtSpfMBLMGaBeZbxsuK2+byny/ukuCxm2C6eihRdft3Rme7SQkn8//Bfm7D7bLaly0S3VB\n8sntBBmZVflpXBXKSE+jZ5vG9GzTmCu+3RE42EW6IOk88e8VPPb+cgA6NMtmQPtc+nkX6TovmQlm\nBtBFUieCX/QjgB8ktJkCXBfenxkCbDWzilweK9jXM5LuJbjJ3wWYXsF91S2ZOdCqTzBFHTgA21aH\nCWfpwS7Wy9+Fuc8cbKd0yO1YtGdbwRlQTrMq/SiuahzZKIvTe7Xi9F6tgKJdpGet3Mz7Szby0sfB\n33c5men0K+w80MS7SNchSUswZpYv6TrgTYJuyhPMbIGkq8P1jwKvE/QgW0rQTXlUwfaSngWGAs0l\nrQbuMLPxks4F/gy0AF6TNMfMTgv3PZmgE0E+cG1pPchcDGnh5bIm7aHzyUXX7dkWOeuJPNuz7B3Y\nn3ew3RFNi088uR19GJ1aJKteOgM6NGVAh6bAoV2kZ63czIPvLOGABSfTXVo2KHIvp5N3ka6V/EHL\n6txNuSY6sB+2fHGwZ1u0i/XO9QfbpdWDpp2KGc2gsw8eWkvtyMtnXowu0gM65NKnbROOyPTx1aqr\nlD8HUxN4gqliu7cU7dlWkHi+Xg4H9h1sl9Pi4ICh0YdKm3SANP+lU1scOGAs27CjyPhqyzYEPR0z\n0kT31o2KJB3vIl19eIKJwRNMNVHc4KEFZ0BFBg+tD82OOfSh0mZdIKtR6uJ3lWbzzr18vGpz4XA3\n0VGkj2qUxYAOufRr38S7SKeYJ5gYPMHUADs3Fe1aXeLgoUcV7VJd8LpRWx88tAaLdpEu6LFWMIp0\n/Yw0erdtXDigZ/8OuTRv4F2kq4InmBg8wdRgsQcPPSI844l2MugcTD54aI0U7SI964vNzF+zlX37\ng99jBV2kCy6rdT3Su0gngyeYGDzB1EIFg4cWSTylDB5aWCAuetbT2h8orUESu0jPWrmlcBTpBvUz\n6NvuYDXQvu2aeBfpSuAJJgZPMHVMkcFDo8/2JA4emnOwREKRez2dg5ESXLVmZqz6eneRzgOLv9xW\n2EW6a8uG9O/QxLtIHwZPMDF4gnFAZPDQSM+2gi7WW1ZxcPBQQZN2xY9m0OBIP+upxnZERpGeXUwX\n6ehQN95FumyeYGLwBOPKFB08tMizPUuLDh5av1Gkd1vkfk/To4NRsV21UtBFOtp5oLgu0gMKukg3\n8TPXKE8wMXiCcRVWMHho4qjVG5cGw+sUUFrw/E60h1vBGVBOcz/rqUaiXaRnrdzM3FVbD+kiXXAv\np3urRnW6i7QnmBg8wbikKDJ4aPSy29KEwUObRDoZRM96OkG634hOtcQu0rNWbmbNFu8iDZ5gYvEE\n46pUcYOHFpwBbY+M8VoweGij1pDdFLKbQ3azyNS06LxXLa0ypXWR7tgsu/A+Tm3vIu0JJgZPMK7a\nOGTw0KWwY30wksGuTbD766JdrKPqZRefeEqcmvoZUiXZs28/89dsjdTKKdpFul/7JoXD3fRr34RG\nWbXje/cEE4MnGFdjHDgAe7YcTDiJ087EZV9D3taS91e/cZBocpqXfGaU3Sw8e2oaXM7zERHKVNBF\netYXXxcOd3NoF+mDnQc6NsuukV2kPcHE4AnG1Wr5e2H35jDhbCyafIokp43hso2Qv6f4fSktKL0Q\nTUY5iZfuEpJUZgPvxEDRLtKzVm7m4y8OdpFumpNJ//ZNCu/l9K4hXaQ9wcTgCca5BHt3HXomVCQ5\nFZOgDuQXv6/0+iWfHeU0L/6MqQ506U7sIj3ri80sj3SR7tG6Ef2qeRdpTzAxeIJx7jCZBWO/FZd4\nChNTwvLdm0veX2aDeB0bCs6ejsitFSUcSusi3apxVpHOA9Whi7QnmBg8wTiXAvvzI5fuirl3VNwl\nvb07StiZ4IgmxSSjUi7fZTWu9pfu9u0/wOJ124sMdxPtIt2n7cHx1fq3b0KzKu4i7QkmBk8wztUQ\n+/YEPekK7xkVd8aUMO3fW/y+0jJKPzvKLubyXTXoCv7l1j2FCWd2CV2kCy6rdWmZ3C7S1SLBSBoG\n/AlIB8aZ2d0J6xWuPwPYBYw0s9nhugnAWcB6M+sZ2aYp8DzQEVgBXGhmmyV1BBYBn4ZNp5rZ1aXF\n5wnGuVrKLDjrSTwz2lnK/aTSuoJnHFFK54amCcmparqCR7tIFySdjTuCpNqwfgZ92x8c0LNvJXeR\nTnmCkZQOfAacAqwGZgAXm9nCSJszgB8TJJghwJ/MbEi47gRgBzAxIcH8HvjazO6WdAuQa2b/EyaY\nV6Nty+IJxjlX6MD+yP2kSuwKXuTeUSnPJx1mV/DELtKzVm7h00gX6W8c2bBI54HD6SIdN8FkVGjv\n8QwGlprZ8jCg54DhwMJIm+EECcSAqZKaSGplZuvM7P0waSQaDgwNXz8FvAf8T1I+gXOu7khLDxNC\nU6BLvG0Ku4KXcma0c2MwUsNXC8rfFby4jg0ldAWXRPtm2bRvls25/doCh3aRfnXeWp6d/gUAp/c8\nikcuHXC431qpkplg2gCrIvOrCc5SymrTBlhHyY40s4L1XwJHRtZ1kjQH2Ar83Mz+lbixpKuAqwDa\nt28f42M451wJMjKh4ZHBFFeRruAbKf5e0tdB7aJV04P5aHnwqPTMUkdtaJDdlOOym3Fc92YwqC0H\nsnqxdHM+s1dupmlOZuV8B6VIZoJJOjMzSQXX+NYB7c1sk6QBwCuSepjZtoRtxgJjIbhEVrURO+fq\nvMzsYGrSLl77EruCF/Pw7JfzSu0KngZ0zWxA1+ym0O0c6HFX5X2uYiQzwawBot9g23BZedsk+qrg\nMpqkVsB6ADPLA/LC17MkLQO6An6TxTlXcynsin1EE2h2TLxtyuwKvjEoGZ5kyUwwM4AukjoRJI0R\nwA8S2kwBrgvvzwwBtkYuf5VkCnAFcHf47/8BSGpBcPN/v6SjCS6iLq+sD+OcczVGegY0aBFMKZS0\nBGNm+ZKuA94k6KY8wcwWSLo6XP8o8DpBD7KlBN2URxVsL+lZgpv5zSWtBu4ws/EEiWWypNHASuDC\ncJMTgDsl7QMOAFeb2dfJ+nzOOedK5w9aejdl55wrl7jdlH38beecc0nhCcY551xSeIJxzjmXFJ5g\nnHPOJYUnGOecc0nhCcY551xS1OluypI2EDxLU1HNgY2VFE5l8rjKx+MqH4+rfGpjXB3MrMynOOt0\ngjlckmbG6Qte1Tyu8vG4ysfjKp+6HJdfInPOOZcUnmCcc84lhSeYwzM21QGUwOMqH4+rfDyu8qmz\ncfk9GOecc0nhZzDOOeeSwhOMc865pPAEUwxJwyR9KmmppFuKWS9JD4Tr50nqH3fbJMd1SRjPJ5I+\nlNQnsm5FuHyOpEqtURAjrqGStobvPUfS7XG3TXJcN0dimi9pv6Sm4bpkfl8TJK2XNL+E9ak6vsqK\nK1XHV1lxper4KiuuKj++JLWT9K6khZIWSPpJMW2q7vgyM58iE0FxtGXA0UAmMBfontDmDOANQMCx\nwLS42yY5rm8DueHr0wviCudXAM1T9H0NBV6tyLbJjCuh/dnAO8n+vsJ9nwD0B+aXsL7Kj6+YcVX5\n8RUzrio/vuLElYrjC2gF9A9fNwQ+S+XvLz+DOdRgYKmZLTezvcBzwPCENsOBiRaYCjSR1CrmtkmL\ny8w+NLPN4exUoG0lvfdhxZWkbSt73xcDz1bSe5fKzN4HSqu2morjq8y4UnR8xfm+SpLS7ytBlRxf\nZrbOzGaHr7cDi4A2Cc2q7PjyBHOoNsCqyPxqDv0BldQmzrbJjCtqNMFfKQUMeFvSLElXVVJM5Ynr\n2+Hp+BuSepRz22TGhaRsYBjw18jiZH1fcaTi+Cqvqjq+4qrq4yu2VB1fkjoC/YBpCauq7PjKOJyN\nXfUk6USCXwDfiSz+jpmtkdQS+LukxeFfYFVhNtDezHZIOgN4BehSRe8dx9nAv80s+tdoKr+vas2P\nr3Kr8uNLUgOChHaDmW2rrP2Wl5/BHGoN0C4y3zZcFqdNnG2TGReSegPjgOFmtqlguZmtCf9dD7xM\ncDpcJXGZ2TYz2xG+fh2oJ6l5nG2TGVfECBIuXyTx+4ojFcdXLCk4vsqUouOrPKr0+JJUjyC5TDKz\nl4ppUnXHV2XfZKrpE8FZ3XKgEwdvdPVIaHMmRW+STY+7bZLjag8sBb6dsDwHaBh5/SEwrArjOoqD\nD/UOBr4Iv7uUfl9hu8YE19FzquL7irxHR0q+aV3lx1fMuKr8+IoZV5UfX3HiSsXxFX7uicD9pbSp\nsuPLL5ElMLN8SdcBbxL0qphgZgskXR2ufxR4naAnxlJgFzCqtG2rMK7bgWbAw5IA8i0YLfVI4OVw\nWQbwjJn9rQrj+j5wjaR8YDcwwoIjOtXfF8C5wFtmtjOyedK+LwBJzxL0fGouaTVwB1AvEleVH18x\n46ry4ytmXFV+fMWMC6r++DoOuAz4RNKccNnPCP44qPLjy4eKcc45lxR+D8Y551xSeIJxzjmXFJ5g\nnP8HSfUAAAHDSURBVHPOJYUnGOecc0nhCcY551xSeIJxroYKRxF+NdVxOFcSTzDOOeeSwhOMc0km\n6VJJ08PaH49JSpe0Q9J9Yc2Of0hqEbbtK2lqOHDjy5Jyw+WdJb0taa6k2ZKOCXffQNKLkhZLmqTw\n6T3nqgNPMM4lkaRuwEXAcWbWF9gPXEIwRMhMM+sB/JPgKXAIhvn4HzPrDXwSWT4JeMjM+hDUZVkX\nLu8H3AB0J6jjcVzSP5RzMflQMc4l10nAAGBGeHJxBLAeOAA8H7Z5GnhJUmOgiZn9M1z+FPCCpIZA\nGzN7GcDM9gCE+5tuZqvD+TkEY2N9kPyP5VzZPME4l1wCnjKzW4sslH6R0K6iYzblRV7vx/9Pu2rE\nL5E5l1z/AL4f1v1AUlNJHQj+730/bPMD4AMz2wpslnR8uPwy4J8WVCZcLel74T7qh0WsnKvW/K8d\n55LIzBZK+jnwlqQ0YB9wLbATGByuW09wnwbgCuDRMIEsJxzpliDZPCbpznAfF1Thx3CuQnw0ZedS\nQNIOM2uQ6jicSya/ROaccy4p/AzGOedcUvgZjHPOuaTwBOOccy4pPME455xLCk8wzjnnksITjHPO\nuaT4/8xK20Gq9YgHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7abc794be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "samples = []\n",
    "i = 0\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        if(i > 0): #this part is added to insure the 1st line in the csvfile which include the headers is not included\n",
    "             samples.append(line)\n",
    "        i = i + 1\n",
    "\n",
    "        \n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# create adjusted steering measurements for the side camera images\n",
    "\n",
    "\n",
    "#images = []\n",
    "#measurments = []\n",
    "# use this section if you wanna use images from the 3-cameras\n",
    "#for line in lines:\n",
    "    #print(line)\n",
    " #   for i in range(3):\n",
    "        # get the image path from the file\n",
    "  #      source_path = line[i]\n",
    "   #     filename = source_path.split('/')[-1]\n",
    "    #    current_path = 'IMG/'+ filename\n",
    "        #print('current_path', current_path)\n",
    "     #   image = cv2.imread(current_path)\n",
    "      #  images.append(image)\n",
    "        # get the steering measurmement (labels) from the file\n",
    "       # measurment = line[3]\n",
    "        #if (i == 0):\n",
    "         #   measurments.append(float(measurment))\n",
    "        #if (i == 1):\n",
    "         #    measurments.append(float(measurment) + correction)\n",
    "        #if (i == 2):\n",
    "         #    measurments.append(float(measurment) - correction)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    correction = 0.1 # this is a parameter to tune\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name_center = 'data/IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name_center)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "                name_left = 'data/IMG/'+batch_sample[1].split('/')[-1]\n",
    "                left_image = cv2.imread(name_left)\n",
    "                left_angle = center_angle + correction\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                name_right = 'data/IMG/'+batch_sample[2].split('/')[-1]\n",
    "                right_image = cv2.imread(name_right)\n",
    "                right_angle = center_angle - correction\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "# display sample image and it's corresponding label (steerng angle)\n",
    "#print(X_train[0].shape, ' shape of train samples')\n",
    "#print(\" a sample of label before flipping\", y_train[4823])\n",
    "#print(\" a sample of label after  flipping\", y_train[4824])\n",
    "#print(\"size of training set\", len(X_train))            \n",
    "\n",
    "\n",
    "\n",
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense  \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocessing the data using Normalization and Mean-Center and using trimmed image format to perform cropping\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0, input_shape=(160, 320, 3)))\n",
    "\n",
    "# Cropping un-useful details from the image to avoid distracting model training. Here I removed 70-pixels from top and 25 pixels from bottom.\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "                    \n",
    "# Using NVIDIA model \n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples)\n",
    "validation_generator = generator(validation_samples)\n",
    "\n",
    "samples_per_epoch = len(train_samples)\n",
    "batch_size = 32\n",
    "steps_per_epoch = samples_per_epoch/batch_size\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "start = time.time()\n",
    "#history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, validation_data=validation_generator,nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "history = model.fit_generator(train_generator, validation_steps=len(validation_samples), steps_per_epoch=steps_per_epoch, epochs=3, validation_data=validation_generator)\n",
    "print(\"Time fit_generator for %s samples: %s\" % (len(train_samples), time.time() - start))\n",
    "\n",
    "# save the model to reuse or download\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()          \n",
    "\n",
    "\n",
    "# NOTE: by default Keras train for 10 epochs\n",
    "\n",
    "# visualize model layout with pydot_ng\n",
    "#plot(model, to_file='model.png', show_shapes=True)\n",
    "print ('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
